# Obtenemos la fórmula:
f.nnet <- as.formula(paste("l1 + l2 + l3 + l4 + l5 + l6 ~",paste(n[!n %in% c("l1","l2","l3","l4","l5","l6")], collapse = " + ")))
testingLearningRate <- function(formula, data,test, ltest){
rates <- seq(from = 0.5, to = 0.6, 0.1)
error <- vector()
pos <- 0
for(i in seq_along(rates)){
print(i)
ann <- neuralnet(formula = formula, data = data, hidden = 5, lifesign = 'minimal', learningrate = rates[i], rep = 3, linear.output = FALSE, stepmax = 10000)
pr.nn <- compute(ann, test)
pr.nn_ <- pr.nn$net.result
original.label <- max.col(ltest[,1])
pr.nn_2 <- max.col(pr.nn_)
error[i] <- 1 - mean(pr.nn_2 == original.label)
print(error[i])
}
return(error)
}
set.seed(123456789)
testingLearningRate(f.nnet, har.data.nnet, har.test, lhar.test.multi01)
testingLearningRate <- function(formula, data,test, ltest){
rates <- seq(from = 0.5, to = 1.5, 0.1)
error <- vector()
pos <- 0
for(i in seq_along(rates)){
ann <- neuralnet(formula = formula, data = data, hidden = 5, lifesign = 'minimal', learningrate = rates[i], rep = 3, linear.output = FALSE, stepmax = 10000)
pr.nn <- compute(ann, test)
pr.nn_ <- pr.nn$net.result
original.label <- max.col(ltest[,1])
pr.nn_2 <- max.col(pr.nn_)
error[i] <- 1 - mean(pr.nn_2 == original.label)
}
return(error)
}
set.seed(123456789)
testingLearningRate(f.nnet, har.data.nnet, har.test, lhar.test.multi01)
set.seed(123456789)
err.tasa <- testingLearningRate(f.nnet, har.data.nnet, har.test, lhar.test.multi01)
errors
err.tasa
lhar.train.multi01 <- class.ind(lhar.train[,1])
lhar.test.multi01 <- class.ind(lhar.test[,1])
har.data.nnet <- cbind(har.train,lhar.train.multi01)
names(har.data.nnet) <- c(names(har.data.nnet)[1:102], "l1", "l2", "l3", "l4", "l5", "l6")
n <- names(har.data.nnet)[1:102]
# Obtenemos la fórmula:
f.nnet <- as.formula(paste("l1 + l2 + l3 + l4 + l5 + l6 ~",paste(n[!n %in% c("l1","l2","l3","l4","l5","l6")], collapse = " + ")))
testingLearningRate <- function(formula, data,test, ltest){
rates <- seq(from = 0.5, to = 1.5, 0.1)
error <- vector()
pos <- 0
for(i in seq_along(rates)){
ann <- neuralnet(formula = formula, data = data, hidden = 5, lifesign = 'minimal', learningrate = rates[i], rep = 3, linear.output = FALSE, stepmax = 10000)
pr.nn <- compute(ann, test)
pr.nn_ <- pr.nn$net.result
original.label <- max.col(ltest[,1])
pr.nn_2 <- max.col(pr.nn_)
error[i] <- 1 - mean(pr.nn_2 == original.label)
print(error[i])
}
return(error)
}
set.seed(123456789)
err.tasa <- testingLearningRate(f.nnet, har.data.nnet, har.test, lhar.test.multi01)
ann <- neuralnet(formula = f.nnet, data = har.data.train, hidden = 5, lifesign = 'minimal', learningrate = 1, rep = 3, linear.output = FALSE, stepmax = 10000)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 1, rep = 3, linear.output = FALSE, stepmax = 10000)
pr.nn <- compute(ann, har.test)
pr.nn_ <- pr.nn$net.result
original.label <- max.col(lhar.test[,1])
pr.nn_2 <- max.col(pr.nn_)
mean(pr.nn_2 == original.label)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 1, rep = 1, linear.output = FALSE, stepmax = 10000)
pr.nn <- compute(ann, har.test)
>
> pr.nn_ <- pr.nn$net.result
>
> original.label <- max.col(lhar.test[,1])
>
> pr.nn_2 <- max.col(pr.nn_)
>
> mean(pr.nn_2 == original.label)
pr.nn_ <- pr.nn$net.result
original.label <- max.col(lhar.test[,1])
pr.nn_2 <- max.col(pr.nn_)
mean(pr.nn_2 == original.label)
pr.nn <- compute(ann, har.test)
pr.nn_ <- pr.nn$net.result
pr.nn_2 <- max.col(pr.nn_)
mean(pr.nn_2 == original.label)
original.label <- max.col(lhar.test[,1])
pr.nn_2 <- max.col(pr.nn_)
mean(pr.nn_2 == original.label)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 1, lifesign = 'minimal', learningrate = 1, rep = 2, linear.output = FALSE, stepmax = 10000)
summary(ann)
ann$response
pr.nn <- compute(ann, test)
pr.nn_ <- pr.nn$net.result
original.label <- max.col(ltest[,1])
pr.nn_2 <- max.col(pr.nn_)
pr.nn <- compute(ann, har.test)
pr.nn <- compute(ann, har.test)
ann
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 1, lifesign = 'minimal', learningrate = 1, rep = 1, linear.output = FALSE, stepmax = 10000)
pr.nn <- compute(ann, test)
testingLearningRate <- function(formula, data,test, ltest){
rates <- seq(from = 0.5, to = 1.2, 0.1)
error <- vector()
original.label <- max.col(ltest[,1])
for(i in seq_along(rates)){
ann <- neuralnet(formula = formula, data = data, hidden = 5, lifesign = 'minimal', learningrate = rates[i], rep = 3, linear.output = FALSE, stepmax = 10000)
pr.nn <- compute(ann, test)
pr.nn_ <- pr.nn$net.result
pr.nn_2 <- max.col(pr.nn_)
error[i] <- 1 - mean(pr.nn_2 == original.label)
print(error[i])
}
return(error)
}
set.seed(123456789)
err.tasa <- testingLearningRate(f.nnet, har.data.nnet, har.test, lhar.test.multi01)
testingLearningRate <- function(formula, data,test, ltest){
rates <- seq(from = 0.8, to = 1.2, 0.1)
error <- vector()
original.label <- max.col(ltest[,1])
for(i in seq_along(rates)){
ann <- neuralnet(formula = formula, data = data, hidden = 5, lifesign = 'minimal', learningrate = rates[i], rep = 3, linear.output = FALSE, stepmax = 10000)
pr.nn <- compute(ann, test)
pr.nn_ <- pr.nn$net.result
pr.nn_2 <- max.col(pr.nn_)
error[i] <- 1 - mean(pr.nn_2 == original.label)
print(error[i])
}
return(error)
}
set.seed(123456789)
err.tasa <- testingLearningRate(f.nnet, har.data.nnet, har.test, lhar.test.multi01)
err.tasa
ann <- neuralnet(formula = formula, data = data, hidden = 5, lifesign = 'minimal', learningrate = rates[i], rep = 1, linear.output = FALSE, stepmax = 10000)
ann <- neuralnet(formula = f.nnet, data = har.train.nnet, hidden = 5, lifesign = 'minimal', learningrate = rates[i], rep = 1, linear.output = FALSE, stepmax = 10000)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = rates[i], rep = 1, linear.output = FALSE, stepmax = 10000)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 1, rep = 1, linear.output = FALSE, stepmax = 10000)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 0.9, rep = 1, linear.output = FALSE, stepmax = 10000)
#La función tuneRF calcula a partir del valor por defecto de mtry el valor óptimo de mtry para el randomForest
#Convertimos la etiqueta a un factor para que haga clasificación
flhar.train <- as.factor(lhar.train[,1])
best.mtry <- tuneRF(har.train, flhar.train, stepFactor = 1, improve = 0.02, ntree = 20)
print("El valor óptimo de mtry calculado es: ")
print(best.mtry)
print("El valor óptimo de mtry calculado es: ")
print(best.mtry[,1])
#La función tuneRF calcula a partir del valor por defecto de mtry el valor óptimo de mtry para el randomForest
#Convertimos la etiqueta a un factor para que haga clasificación
flhar.train <- as.factor(lhar.train[,1])
best.mtry <- tuneRF(har.train, flhar.train, stepFactor = 1, improve = 0.02, ntree = 50)
print("El valor óptimo de mtry calculado es: ")
print(best.mtry[,1])
best.params <- tune(method = randomForest, har.train, flhar.train, ranges = list(ntree = c(10,20,30,40,50,70,80,90,100), mtry = 10), tunecontrol = tc)
best.params
best.params <- tune(method = randomForest, har.train, flhar.train, ranges = list(ntree = c(,50,70,80,90,100,110,120,130,140,150), mtry = 10), tunecontrol = tc)
best.params <- tune(method = randomForest, har.train, flhar.train, ranges = list(ntree = c(50,70,80,90,100,110,120,130,140,150), mtry = 10), tunecontrol = tc)
best.params
best.params <- tune(method = randomForest, har.train, flhar.train, ranges = list(ntree = c(50,100,150,200,250), mtry = 10), tunecontrol = tc)
best.params
best.params <- tune(method = randomForest, har.train, flhar.train, ranges = list(ntree = c(250,500), mtry = 10), tunecontrol = tc)
best.params
best.params <- tune(method = randomForest, har.train, flhar.train, ranges = list(ntree = c(250,500,1000), mtry = 10), tunecontrol = tc)
best.params
set.seed(123456789)
best.params <- tune(method = randomForest, har.train, flhar.train, ranges = list(ntree = c(2000,1000), mtry = 10), tunecontrol = tc)
best.params
best.params$best.parameters
best.params$performances
best.params <- tune(method = randomForest, har.train, flhar.train, ranges = list(ntree = c(50,100,150,200,150,300,350,400,450,500), mtry = 10), tunecontrol = tc)
best.params$performances[2]
best.params$performances[3]
plot(best.params$performances[3])
best.params$performances
plot(best.params$performances[1],best.params$performances[3])
plot(c(best.params$performances[1],best.params$performances[3]))
points <- best.params$performances[c(1,3)]
points
plot(points)
plot(points, type = "l", col = "blue")
best.params <- tune(method = randomForest, har.train, flhar.train, ranges = list(ntree = c(100,200,300,400,500, 600, 700, 800, 900, 1000), mtry = 10), tunecontrol = tc)
best.params
print(best.params$performances)
print(best.params$best.performances)
print(best.params$best.performance)
print(best.params)
points <- best.params$performances[c(1,3)]
plot(points, type = "l", col = "blue")
rf_model <- randomForest(x = har.train, y = flhar.train, ntree = 800, mtry = 10)
rf.pred <- predict(rf_model,har.test)
Eou.rf
Eout.rf
Eout.rf <- sum(rf.pred != lhar.test[,1])/length(rf.pred)
Eout.rf
har.data.nnet <- cbind(har.train,lhar.train)
dim(har.data.nnet)
names(har.data.nnet) <- c(names(har.data.nnet)[1:102], "l")
n <- names(har.data.nnet)[1:102]
f.nnet <- as.formula(paste("l ~",paste(n[!n %in% c("l")], collapse = " + ")))
testingLearningRate <- function(formula, data,test, ltest){
rates <- seq(from = 0.8, to = 1.2, 0.1)
error <- vector()
original.label <- max.col(ltest[,1])
for(i in seq_along(rates)){
ann <- neuralnet(formula = formula, data = data, hidden = 5, lifesign = 'minimal', learningrate = rates[i], rep = 3, linear.output = FALSE, stepmax = 10000)
pr.nn <- compute(ann, test)
pr.nn_ <- pr.nn$net.result
pr.nn_2 <- max.col(pr.nn_)
error[i] <- 1 - mean(pr.nn_2 == original.label)
}
return(error)
}
err.tasa <- testingLearningRate(f.nnet, har.data.nnet, har.test, lhar.test)
err.tasa
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 2, rep = 3, linear.output = FALSE, stepmax = 10000)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'full', learningrate = 2, rep = 3, linear.output = FALSE, stepmax = 10000)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'full', learningrate = 2, rep = 3, linear.output = FALSE, stepmax = 10000, threshold = 0.0001)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 20, lifesign = 'full', learningrate = 2, rep = 3, linear.output = FALSE, stepmax = 10000, threshold = 0.0001)
pr.nn <- compute(ann, har.test)
pr.nn_ <- pr.nn$net.result
pr.nn_2 <- max.col(pr.nn_)
original.label <- max.col(lhar.test[,1])
1 - mean(pr.nn_2 == original.label)
mean(pr.nn_2 == original.label)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 100, lifesign = 'full', learningrate = 2, rep = 3, linear.output = FALSE, stepmax = 10000, threshold = 0.0001)
pr.nn <- compute(ann, har.test)
pr.nn_ <- pr.nn$net.result
pr.nn_2 <- max.col(pr.nn_)
mean(pr.nn_2 == original.label)
ann
ann$result.matrix
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = c(10,10,10), lifesign = 'full', learningrate = 2, rep = 3, linear.output = FALSE, stepmax = 10000, threshold = 0.0001)
pr.nn <- compute(ann, har.test)
pr.nn_ <- pr.nn$net.result
pr.nn_2 <- max.col(pr.nn_)
mean(pr.nn_2 == original.label)
pred <- prediction(ann, har.test)
lhar.train.multi01 <- class.ind(lhar.train[,1])
lhar.test.multi01 <- class.ind(lhar.test[,1])
har.data.nnet <- cbind(har.train,lhar.train.multi01)
names(har.data.nnet) <- c(names(har.data.nnet)[1:102], "l1", "l2", "l3", "l4", "l5", "l6")
n <- names(har.data.nnet)[1:102]
f.nnet <- as.formula(paste("l1 + l2 + l3 + l4 + l5 + l6 ~",paste(n[!n %in% c("l1","l2","l3","l4","l5","l6")], collapse = " + ")))
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 1, rep = 1, linear.output = FALSE, stepmax = 10000)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 2, rep = 1, linear.output = FALSE, stepmax = 10000)
pr.nn <- compute(ann, har.test)
pr.nn_ <- pr.nn$net.result
pr.nn_2 <- max.col(pr.nn_)
original.label <- max.col(lhar.test.multi01[,1])
mean(pr.nn_2 == original.label)
pr.nn_2
maboost_model <- maboost(x = har.train, y = as.factor(lhar.train[,1]), sparsefactor = TRUE)
maboost.pred <- predict(maboost_model,har.test)
Eout.maboost <- sum(maboost.pred != lhar.test[,1])/length(maboost.pred)
confussion.maboost <- table(maboot.pred,lhar.test[,1])
confussion.maboost <- table(maboot.pred,lhar.test[,1])
maboost.pred <- predict(maboost_model,har.test)
confussion.maboost <- table(maboost.pred,lhar.test[,1])
Eout.maboost
confussion.maboost
pr.nn_
pr.nn_2
pr.nn_2 <- min.col(pr.nn_)
pr.nn_2 <- max.col(pr.nn_)
?max.col
pr.nn_
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 1, rep = 3, linear.output = FALSE, act.fct = "logistic", stepmax = 50000)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 1, rep = 1, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 2, rep = 1, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 3, lifesign = 'minimal', learningrate = 2, rep = 1, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
tc <- tune.control(cross = 5)
svm_tune <- tune(svm, train.x = har.train, train.y = factor(lhar.train[,1]), kernel = "radial", ranges = list(gamma=c(0.01,0.1,1,10)), tunecontrol = tc)
svm_tune
svm_model <- svm(x = har.train, y = factor(lhar.train[,1]), kernel = "radial", gamma = 0.1)
summary(svm_model)
svm.pred <- predict(svm_model,har.test)
Eout.svm <- sum(svm.pred != lhar.test[,1])/length(svm.pred)
confussion.svm <- table(svm.pred,lhar.test[,1])
Eout.svm
Eout.rg
Eout.rf
confussion.svm
svm_model <- svm(x = har.train, y = factor(lhar.train[,1]), kernel = "radial", gamma = 0.01)
svm.pred <- predict(svm_model,har.test)
Eout.svm <- sum(svm.pred != lhar.test[,1])/length(svm.pred)
confussion.svm <- table(svm.pred,lhar.test[,1])
Eout.svm
confussion.svm
ls(pr.nn)
return(which(arr = max(arr)))
maxid <- function(arr){
return(which(arr = max(arr)))
}
idx <- apply(pr.nn_, c(1), maxid)
pr.nn_ <- pr.nn$net.result
idx <- apply(pr.nn_, c(1), maxid)
max(pr.nn_)
maxidx <- function(arr) {
return(which(arr == max(arr)))
}
idx <- apply(pr.nn_, c(1), maxid)
which(lhar.train == 1)
maX(lhar.train)
max(lhar.train)
which(lhar.train == max(har.train))
which(lhar.train == max(lhar.train))
?applyy
?apply
idx <- apply(pr.nn_, 1, maxid)
pr.nn_
dim(pr.nn_)
maxidx <- function(arr) {
return(which(arr == max(arr)))
}
idx <- apply(pr.nn_, c(1), maxidx)
prediction <- c('1', '2', '3','4','5','6')[idx]
prediction
table(prediction, lhar.test)
table(prediction, lhar.test)
table(prediction, lhar.test.multi01)
dim(prediction)
length(prediction)
dim(lhar.test.multi01)
table(prediction, c(1,2,3,4,5,6))
idx
pr.nn_2
ann <- neuralnet(formula = f.nnet, data = har.train, hidden = 3, lifesign = 'minimal', learningrate = 1, rep = 1, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 3, lifesign = 'minimal', learningrate = 1, rep = 1, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
original.label <- max.col(ltest[,1])
original.label <- max.col(lhar.test.multi01[,1])
original.label
original.label <- max.col(lhar.test[,1])
original.label
lhar.test
original.label <- max.col(lhar.test[,1])
original.label
mean(pr.nn_2 == lhar.test)
testingLearningRate <- function(formula, data,test, ltest){
rates <- seq(from = 0.8, to = 1.2, 0.1)
error <- vector()
for(i in seq_along(rates)){
ann <- neuralnet(formula = formula, data = data, hidden = 5, lifesign = 'minimal', learningrate = rates[i], rep = 3, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
pr.nn <- compute(ann, test)
pr.nn_ <- pr.nn$net.result
pr.nn_2 <- max.col(pr.nn_)
error[i] <- 1 - mean(pr.nn_2 == ltest)
}
return(error)
}
err.tasa <- testingLearningRate(f.nnet, har.data.nnet, har.test, lhar.test)
err.tasa
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 1, rep = 1, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
set.seed(123456789)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 1, rep = 1, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
set.seed(1)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 1, rep = 1, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
pr.nn <- compute(ann, har.test)
pr.nn_ <- pr.nn$net.result
pr.nn_2 <- max.col(pr.nn_)
1 - mean(pr.nn_2 == lhar.test)
har.train.data[,c(1,2)]
har.data.nnet[,c(1,2)]
har.data.nnet[c(1,2),]
lhar.data[c(1,2)]
lhar.train[c(1,2)]
lhar.train[,c(1,2)]
lhar.train[c(1,2),]
testingLearningRate <- function(formula, data,ldata){
rep <- sample(nrow(data), 0.3*nrow(data))
train <- data[-rep,]
test <- data[rep,]
ltest <- ldata[rep,]
rates <- seq(from = 0.8, to = 1.2, 0.1)
error <- vector()
for(i in seq_along(rates)){
ann <- neuralnet(formula = formula, data = train, hidden = 5, lifesign = 'minimal', learningrate = rates[i], rep = 3, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
pr.nn <- compute(ann, test)
pr.nn_ <- pr.nn$net.result
pr.nn_2 <- max.col(pr.nn_)
error[i] <- 1 - mean(pr.nn_2 == ltest)
}
return(error)
}
set.seed(123456789)
err.tasa <- testingLearningRate(f.nnet, har.data.nnet, har.test, lhar.test)
err.tasa <- testingLearningRate(f.nnet, har.data.nnet)
err.tasa <- testingLearningRate(f.nnet, har.data.nnet,lhar.train)
testingLearningRate <- function(formula, data,ldata){
rep <- sample(nrow(data), 0.3*nrow(data))
train <- data[-rep,]
test <- data[rep,(1:102)]
ltest <- ldata[rep,]
rates <- seq(from = 0.8, to = 1.2, 0.1)
error <- vector()
for(i in seq_along(rates)){
ann <- neuralnet(formula = formula, data = train, hidden = 5, lifesign = 'minimal', learningrate = rates[i], rep = 3, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
pr.nn <- compute(ann, test)
pr.nn_ <- pr.nn$net.result
pr.nn_2 <- max.col(pr.nn_)
error[i] <- 1 - mean(pr.nn_2 == ltest)
}
return(error)
}
set.seed(123456789)
err.tasa <- testingLearningRate(f.nnet, har.data.nnet,lhar.train)
err.tasa.rate <- cbind(c(0.8,0.9,1,1.1,1.2), err.tasa)
print(err.tasa.rate)
set.seed(1)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 1, rep = 1, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
set.seed(1)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 1.1, rep = 1, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
err.tasa.rate <- cbind(c("Tasa de aprendizaje", 0.8,0.9,1,1.1,1.2),  err.tasa)
print(err.tasa.rate)
err.tasa.rate <- cbind(c(0.8,0.9,1,1.1,1.2),  err.tasa)
print(err.tasa.rate)
set.seed(123456789)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 1.1, rep = 1, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
set.seed(996)
set.seed(996)
ann <- neuralnet(formula = f.nnet, data = har.data.nnet, hidden = 5, lifesign = 'minimal', learningrate = 1.1, rep = 1, linear.output = FALSE, act.fct = "logistic", stepmax = 10000)
pr.nn <- compute(ann, har.test)
pr.nn_ <- pr.nn$net.result
pr.nn_2 <- max.col(pr.nn_)
Eout.nn <- 1 - mean(pr.nn_2 == ltest)
Eout.nn <- 1 - mean(pr.nn_2 == lhar.test)
Eout.nn
table(pr.nn_2, lhar.test)
length(pr.nn_2)
length(lhar.test)
table(pr.nn_2, lhar.test[,2])
table(pr.nn_2, lhar.test[,1])
Eout.nn
Eout.rf
Eout.svm
Eout.boost
Eout.maboost
dim(pr.nn_)
dim(ann$weights)
ann
ann$weights
length(ann$weights)
plot(rf_model)
getTree(rf, 1, labelVar=TRUE)
getTree(rf_model, 1, labelVar=TRUE)
?plot.maboost
?plot.svm
plot(svm_model)
plot(svm_model, har.train, PCA1 ~ PCA2)
summary(har.train)
attach(har.train)
plot(svm_model, har.train, PCA1 ~ PCA2)
plot(svm_model, har.train)
plot(svm_model, har.train, svSymbol = 1, dataSymbol = 2, symbolPalette = rainbow(4),
color.palette = terrain.colors)
f.aux <- as.formula(paste("l1~",paste(n[n %in% c("l2")], collapse = " + ")))
lhar.train.multi01 <- class.ind(lhar.train[,1])
lhar.test.multi01 <- class.ind(lhar.test[,1])
har.data.nnet <- cbind(har.train,lhar.train.multi01)
names(har.data.nnet) <- c(names(har.data.nnet)[1:102], "l1", "l2", "l3", "l4", "l5", "l6")
n <- names(har.data.nnet)[1:102]
f.aux <- as.formula(paste("l1~",paste(n[n %in% c("l2")], collapse = " + ")))
f.aux <- as.formula("l1  ~ l2")
plot(svm_model, har.train, f.aux)
plot(svm_model, har.train.nnet, f.aux)
plot(svm_model, har.data.nnet, f.aux)
summary(har.data.nnet)
plot(har.train)
summary(svm_model)
confussion.svm
?maboost
plot(points, type = "l", col = "blue")
plot(points, type = "l", col = "blue")
confussion.lineal
confussion.nn
confusion.nn
confusion.nn <- table(pr.nn_2, lhar.test[,1])
confusion.nn
confussion.svm
confussion.rf
confussion.adabgm
confussion.maboost
rf.pred <- predict(rf_model,har.test)
Eout.rf <- sum(rf.pred != lhar.test[,1])/length(rf.pred)
confussion.rf <- table(rf.pred,lhar.test[,1])
confussion.rf
svm_tune
svm_model
set.seed(123456789)
rf_model <- randomForest(x = har.train, y = flhar.train, ntree = 500, mtry = 10)
library(randomForest)
rf_model <- randomForest(x = har.train, y = flhar.train, ntree = 500, mtry = 10)
flhar.train <- as.factor(lhar.train[,1])
rf_model <- randomForest(x = har.train, y = flhar.train, ntree = 500, mtry = 10)
rf.pred <- predict(rf_model,har.test)
confussion.rf <- table(rf.pred,lhar.test[,1])
print("Etest obtenido en Random Forest:")
print(Eout.rf)
Eout.rf <- sum(rf.pred != lhar.test[,1])/length(rf.pred)
confussion.rf <- table(rf.pred,lhar.test[,1])
print(Eout.rf)
?write
?write.table
train
train = read.csv("../train.csv", header = TRUE, sep = ",")
setwd("~/Desktop/Universidad/IN/P3/Versión 27")
train = read.csv("../train.csv", header = TRUE, sep = ",")
sumamry(train)
summary(train)
train['Electrical']
